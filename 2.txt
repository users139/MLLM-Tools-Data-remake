赋予大型语言模型工具调用能力：方法、挑战与前沿展望
1. 引言：工具调用对于高级大型语言模型 (LLM) 的重要性
1.1. 工具调用的定义及其意义
工具调用（Tool Calling），亦称为函数调用（Function Calling），是指人工智能 (AI) 模型，特别是大型语言模型 (LLM)，与外部工具、应用程序编程接口 (API) 或系统交互以增强其功能的能力 。与仅仅依赖预训练知识不同，具备工具调用能力的 AI 系统可以查询数据库、获取实时信息、执行函数或执行超出其固有能力的复杂操作 。这种能力将 LLM 从文本生成器转变为能够采取行动的智能体 。
此能力的至关重要性体现在，LLM 传统上受限于其训练数据，而训练数据的更新过程既耗时又计算密集 。工具调用弥合了自然语言理解与实际任务执行之间的鸿沟 。传统 LLM 主要基于其训练数据中的模式生成响应，这本质上是一种被动的信息处理方式 。工具调用则允许 LLM 与外部系统交互，执行函数，并检索实时数据 。这种主动交互使得 LLM 能够影响外部世界或收集其内部知识库之外的信息。因此，工具调用从根本上改变了 LLM 的角色，使其从被动的信息检索者/生成者转变为能够在动态环境中执行任务和解决问题的主动参与者。这一转变开启了广泛的新应用前景，从自动化工作流程、与数据库交互 ，到控制物联网设备或执行复杂的多步骤问题解决。
1.2. 扩展 LLM 能力超越预训练知识
LLM 的预训练知识是静态的，并且可能随着时间的推移而过时 。工具调用允许它们访问实时数据库、进行实时计算并获取最新信息 ，从而克服这些局限性。它使 LLM 能够提供更准确、最新和动态的响应 。超越静态训练数据的能力对于信息不断变化的现实世界应用（例如天气、股票价格、库存）至关重要。
LLM 的训练数据截至特定时间点（即知识截止期）。对于需要知识截止期之后的信息或高度动态数据的查询，仅凭预训练知识无法准确回答 。工具调用允许 LLM 访问提供当前信息的外部工具（例如，网络搜索、天气 API）。通过调用这些工具，LLM 可以获取实时数据并将其整合到响应中。因此，工具调用可作为 LLM 知识库的动态扩展，减轻了知识截止期带来的限制。这使得 LLM 在需要当前信息的任务中更为实用，增强了其在实际场景中的可靠性和适用性。
2. LLM 工具调用的核心机制
2.1. 识别工具需求
该过程始于 LLM 使用自然语言理解 (NLU) 来确定用户的请求是否需要其静态知识无法满足的外部信息或操作 。例如，诸如“现在旧金山的天气如何？”之类的查询会触发对实时数据的需求 。此步骤对于 LLM 决定何时使用工具至关重要，可防止不必要的工具调用并确保高效操作。
LLM 首先使用其 NLU 功能处理用户提示 。它必须区分可以从其内部知识回答的查询和需要外部交互的查询。模糊的提示或复杂的查询可能会使 LLM 更难准确确定是否需要工具。NLU 的质量（通过预训练和可能的微调得到改进）决定了此决策的准确性。因此，初始“需求识别”步骤的有效性与 LLM 的语言理解能力成正比。此步骤中的失败可能导致 LLM 在应该使用工具时未使用工具（导致答案不完整或不正确），或者不必要地尝试使用工具（导致效率低下）。这凸显了强大的 NLU 作为工具调用基础的重要性。
2.2. 工具选择与参数构建
一旦识别出需求，AI 就会从一组可用工具中确定任务的最佳工具 。每个工具都通过元数据定义：唯一的名称（或函数名称）、其用途描述以及其参数的模式（通常是 JSON 模式）。LLM 会生成与所选工具参数的模式相匹配的结构化输出（例如 JSON）。准确的工具选择和正确的参数生成对于工具成功执行并产生预期结果至关重要。工具的描述在帮助 LLM 做出正确选择方面起着至关重要的作用 。
LLM 使用工具的名称、描述和参数模式来理解工具的功能及其所需的输入 。模糊或不准确的描述可能导致 LLM 选择错误的工具或误解其用途。不完整或不正确的参数模式可能导致 LLM 生成无效参数，从而导致工具执行失败。因此，这些定义充当了关键接口；其清晰度和精确度直接影响工具调用的可靠性。这表明“工具定义工程”与提示工程对于有效的工具使用同等重要。开发人员必须投入大量精力来创建清晰、全面且准确的工具定义。这可能涉及迭代优化和测试，以确保 LLM 正确解释它们。这也意味着随着工具的演变，必须仔细更新其描述。
2.3. 生成用于工具执行的结构化输出
LLM 本身不执行工具。相反，它会生成结构化输出（通常是 JSON），其中包含要调用的函数的名称以及要传递给它的参数 。然后，应用程序代码使用此结构化数据来实际进行 API 调用或运行函数 。通常会分配一个唯一的工具调用 ID 来跟踪请求及其结果 。这种关注点分离（LLM 生成意图，应用程序执行）是一种常见且强大的架构模式。结构化输出可确保 LLM 与外部系统之间的可靠通信。
LLM 的任务是生成符合严格模式（例如，工具参数的 JSON 模式）的输出 。此输出不是自然语言，而是用于机器解析和执行的数据格式。根据模式生成语法和语义正确的 JSON 类似于生成小型、特定的代码片段或数据结构。为函数调用而微调的模型专门训练以擅长这种结构化数据生成 。因此，启用工具调用通常涉及增强或利用 LLM 将自然语言意图转换为机器可读的结构化格式的能力。这突显了为什么对包含正确结构化输出示例的数据集进行微调可以显著提高工具调用的可靠性。它还表明，用于改进 LLM 中代码生成的技术可能适用于改进工具调用的结构化数据生成。
3. 在 LLM 中启用工具调用的方法论
3.1. 提示工程策略
3.1.1. 构建有效的工具描述和提示
提示工程涉及策略性地设计特定于任务的指令，以引导模型输出而无需更改模型参数 。对于工具调用，这包括在提示中提供清晰的工具定义（名称、描述、参数）。模板可以构建提示格式，以告知模型使用哪个工具以及提供哪些参数 。精心设计的提示是启用工具调用的最简单方法，特别是对于具有固有指令遵循能力的模型。
3.1.2. 高级提示技术（例如 ReAct, Zero-Shot）
 * Zero-Shot 提示： LLM 可以遵循抽象指令而无需示例，这对于难以提供示例的复杂任务非常有用 。通过提供有关“思考/行动/观察”周期的详细说明，可以将 ReAct 与 Zero-Shot 结合实施 。
 * ReAct (Reasoning and Acting)： 该框架提示 LLM 以交错方式生成推理轨迹和特定于任务的动作 。这使模型能够引导、跟踪和更新行动计划，处理异常情况，并整合来自外部工具的信息 。它旨在通过与外部来源（例如维基百科 API）交互来减少幻觉和错误传播 。
像 ReAct 这样的高级技术增强了 LLM 执行多步推理和更稳健地与工具交互的能力，特别是对于复杂任务。
3.1.3. 提示工程的优缺点
 * 优点：
   * 灵活性和快速迭代： 无需重新训练模型即可快速修改和测试提示 。
   * 无需模型再训练： 利用现有模型功能，节省训练的计算资源 。
 * 缺点：
   * 上下文长度限制： 复杂的工具描述或许多工具可能会超出 LLM 的上下文窗口 。
   * 潜在的不一致性： 性能可能对提示措辞敏感；LLM 可能并不总是可靠地遵循工具使用说明 。
   * 依赖 LLM 的固有理解： 成功取决于基础模型解释指令和推理工具使用的能力 。
用于工具调用的提示工程是在提供足够指导和避免 LLM 过载之间进行的高杠杆但微妙的平衡行为，而像 ReAct 这样的高级技术试图为更复杂的任务构建这种交互结构。简单的提示易于实现，但可能缺乏在不同场景下可靠使用工具的特异性 。带有明确工具描述和模式的详细提示可提高可靠性，但会消耗上下文长度 。像 ReAct  这样的技术引入了一个结构化的思考-行动-观察循环，为 LLM 提供了一个元认知框架。这有助于更有效地分解复杂任务和集成工具使用。然而，即使是 ReAct 也有局限性，例如对工具检索到的信息质量敏感 。这意味着虽然提示提供了一个低门槛的入门方式，但仅通过提示实现强大且可扩展的工具调用需要复杂的提示设计和对 LLM 推理局限性的理解。提示的局限性通常会促使人们探索微调或预训练。
3.2. 微调 LLM 以增强工具交互
3.2.1. 使用工具使用数据进行监督微调 (SFT)
微调通过在较小的标记数据集上进一步训练预训练模型来使其适应特定任务 。对于工具调用，这涉及提示-响应对的数据集，其中“响应”是工具调用的正确结构化输出（例如 JSON）。这有助于模型学习生成正确的函数和参数 。指令微调是一项关键策略 。SFT 可以“植入”特定工具及其使用模式的知识，从而比单独提示更可靠、更准确地调用工具。
3.2.2. 参数高效微调 (PEFT) 方法
全量微调可能会消耗大量资源，因为它会更新所有模型权重 。PEFT 方法（例如 LoRA，像 PLUG 这样的适配器 ）仅更新一小部分参数，使微调更易于访问，并降低灾难性遗忘的风险。列出了几种用于工具调用的 PEFT 策略，例如 Gpt4tools 和 CITI 。PEFT 通过降低计算和内存需求，使许多组织更容易实现针对工具调用的微调。
3.2.3. 数据集管理和最佳实践
对于微调数据集而言，质量胜于数量；几十个清晰、切题的样本可能胜过数百个平庸的样本 。数据集通常由提示-响应对组成 。集成指令遵循数据可以提高函数调用准确性和相关性检测 。由专有模型（例如 GPT-4）生成的合成数据通常用于为工具调用创建微调数据集（例如 ToolAlpaca, ToolLlama）。微调数据集的质量和组成是决定模型微调后工具调用性能的关键因素。
3.2.4. 微调的优缺点
 * 优点：
   * 提高特定工具的可靠性： 模型学习其微调所用工具的特定模式和模式 。
   * “植入式”知识： 工具使用更深入地融入模型的行为中 。
   * 更好的相关性检测： 微调可以提高模型判断何时适合进行工具调用的能力，尤其是在与指令遵循数据和特定技术（如“决策令牌”）结合使用时 。
 * 缺点：
   * 数据和计算密集型： 需要精选的数据集和大量的计算资源，尤其是对于全量微调 。
   * 灾难性遗忘的风险： 对狭窄任务进行微调有时会降低通用任务的性能，尽管 PEFT 可以缓解这种情况。
   * 对新工具/已更改工具的适应性较差： 模型针对其微调数据集中的工具进行了优化。添加新工具或处理对现有工具的重大更改通常需要重新训练或进一步微调。
微调为一组定义的工具创建了一个“专业化专家”LLM，用专家可靠性换取了提示的通用灵活性，但这种专业化带来了不断演变的工具集的维护开销。微调会针对特定任务和数据分布（在本例中为工具调用场景）优化模型的权重 。这导致已知工具的准确性和可靠性更高 。然而，这种优化使得模型对在微调期间未见过的工具或工具使用模式的固有适应性降低。如果工具的 API 发生更改或引入了新工具，微调模型的“植入式”知识可能会过时或不完整，需要新的微调周期。因此，虽然微调为特定领域产生了更可靠的工具用户，但它引入了对该领域稳定性的依赖以及持续维护的需求。选择微调的组织还必须计划一个持续的 MLOps 周期，以便随着其工具生态系统的发展更新数据集和重新训练模型。PEFT  可以使此过程更易于管理，但并不能消除这种需求。
3.3. 用于基础工具意识的预训练和持续预训练
3.3.1. 通用预训练的作用
初始预训练阶段通过处理大量文本数据为 LLM 配备通用语言理解能力 。这包括学习语法、事实和常见的语言模式 。当 LLM 尝试理解工具描述和用户意图以进行工具调用时，会利用这种基础知识。在有效应用任何特定的工具调用启用方法之前，来自预训练的强大基础模型至关重要。
3.3.2. 使用工具特定数据进行持续预训练
持续预训练（或领域自适应预训练）旨在整合来自不同领域的新信息，同时保留先前学习的知识 。虽然许多研究侧重于下游任务，但该概念可以扩展到包含与工具使用相关的数据，从而可能使 LLM 对工具如何运作或 API 调用如何构建具有更固有的意识。这是一种资源密集型方法，但可以在模型中构建更基本的工具理解。
3.3.3. 新兴范式（例如 ToolGen：将工具集成为令牌）
ToolGen 提出通过将每个工具表示为 LLM 词汇表中的唯一虚拟令牌，将工具知识直接集成到 LLM 参数中 。然后训练 LLM 在其下一令牌预测中生成这些工具令牌及其参数，从而将工具检索和调用统一到生成任务中。这种方法旨在允许 LLM 无需单独的检索步骤即可访问大量工具 。这是一个与基于提示或传统微调方法显著不同的方法，并且可以为非常大的工具集提供更好的可扩展性。它解决了 LLM 及其分词器主要在自然语言数据而非工具功能上进行预训练的局限性 。
3.3.4. 预训练/持续预训练的优缺点
 * 优点：
   * 潜在的广泛工具理解： 如果包含多样化的工具相关数据，可能会导致更通用的工具使用能力。
   * 许多工具的可扩展性 (ToolGen)： 将工具表示为令牌可以克服上下文长度问题和大型工具集的低效检索 。
   * 更集成的知识： 工具意识成为模型核心参数的一部分 。
 * 缺点：
   * 极其耗费资源： 预训练甚至显著的持续预训练都需要海量数据集和计算能力 。
   * 可能仍需要微调： 来自预训练的通用工具意识可能仍需要通过微调来针对特定的复杂工具交互进行磨练。
   * 新颖性和复杂性： 像 ToolGen 这样的方法较新，可能存在其自身的实施挑战。
在预训练或持续预训练层面整合工具知识，特别是通过像 ToolGen 这样的创新分词策略，代表了使 LLM “工具原生”而非仅仅“工具感知”的根本转变，这可能解决深层次的可扩展性和效率问题。提示和微调将工具视为外部实体，LLM 通过上下文指令或专门的训练数据学习与之交互 。由于上下文限制或需要大量微调数据，这些方法可能难以处理大量工具 。ToolGen 将工具表示为唯一令牌的方法  有效地使“调用工具”成为 LLM 词汇和生成过程的一部分，类似于生成任何其他单词或短语。这将工具知识更深入地内化到模型的参数中。这种方法可以在许多情况下绕过工具选择的显式检索步骤，并允许 LLM 作为连续思维过程的一部分“原生”决定使用工具并生成其调用。如果成功且可扩展，这可以极大地提高 LLM 使用大量不同工具的效率和能力。它预示着未来 LLM 不仅仅是语言模型，而是具有内置外部交互机制的更通用的推理引擎。然而，这种预训练的成本和复杂性是巨大的。
4. 比较分析：为工具调用选择正确的方法
4.1. 基于任务复杂度、可扩展性和资源可用性评估方法
本节将综合先前讨论的优缺点。对于工具数量少且稳定的简单任务，提示工程可能是一个不错的选择。对于已知工具集且需要高可靠性的复杂任务，微调可能更有益。对于具有极其庞大、动态工具集的场景，最终可能需要预训练级别的解决方案。资源可用性（计算、数据、专业知识）将严重影响可行选项的选择。为从业者提供清晰的决策框架至关重要。
4.2. 混合方法：结合优势以获得最佳性能
通常，最佳解决方案涉及多种方法的结合。例如，使用具有一定持续预训练的基础模型以获得通用工具意识，然后针对一组特定的关键工具对其进行微调，最后使用复杂的提示（如 ReAct）以获得运行时灵活性。RAG 可以与任何这些方法结合使用，为工具提供最新信息或帮助选择工具 。混合方法可以在可靠性、灵活性和资源效率之间取得平衡。
提示、微调和预训练之间的界限正在变得模糊，混合方法和像 RAG 这样的技术正在成为在工具调用中平衡性能、成本和适应性的实用解决方案。每种主要方法（提示、微调、预训练）都有其独特的优缺点（如第 3 节所述）。没有一种方法适用于所有工具调用场景。例如，RAG 可以通过动态提供相关的工具描述来增强提示，或者可以通过获取工具需要处理的数据来补充微调模型 。一个模型可能经过通用预训练，然后在核心工具调用功能集上进行微调，并且仍然依赖运行时提示进行新颖或不太频繁的工具交互。这表明了一种趋势，即模块化和分层架构，其中不同的技术应用于工具调用过程的不同阶段或不同方面。开发人员应将这些方法视为一个工具包，而不是相互排斥的选项。最佳架构可能需要根据特定应用程序对准确性、延迟、成本和可维护性的要求进行深思熟虑的组合。
表 1：工具调用启用方法比较概览
| 特性/方法 | 提示工程 (Prompt Engineering) | 微调 (Fine-Tuning) (SFT/PEFT) | 预训练/持续预训练 (Pre-training/Continued Pre-training) (含 ToolGen 类概念) |
|---|---|---|---|
| 核心特点 | 通过指令引导模型行为，不改变模型参数  | 在特定数据集上进一步训练模型，调整模型权重  | 将工具知识更基础地融入模型参数，可能改变词汇表  |
| 主要优势 | 灵活性高，迭代速度快，无需模型再训练  | 对特定工具的可靠性高，“植入式”知识 ；PEFT 资源效率较高 | 潜在的广泛工具理解能力，对大量工具的可扩展性 (ToolGen)  |
| 主要劣势 | 上下文长度限制，对提示敏感，一致性可能不足  | 数据和计算密集 (SFT)，有灾难性遗忘风险，对新工具适应性差  | 极其耗费资源，技术较新，可能仍需后续微调  |
| 典型用例 | 简单任务，工具集稳定，快速原型验证 | 复杂任务，对特定工具可靠性要求高，工具集相对固定 | 需要处理海量工具，追求更深层次工具集成和理解的场景 |
| 资源强度 (数据、计算、专业知识) | 低 | 中到高 (SFT 高, PEFT 中) | 非常高 |
| 对新工具的适应性 | 较高（通过修改提示），但对全新功能可能受限 | 低（通常需要重新微调） | 中到高（取决于具体实现，ToolGen 设计目标是高适应性） |
| 可靠性 | 中等，高度依赖提示质量和模型固有能力 | 高（针对微调过的工具） | 潜力高，但具体取决于训练数据和方法 |
5. 应对工具生态系统中的挑战
5.1. 管理差异：训练工具集与操作工具集
训练或微调期间可用的工具集可能与实际环境中所需的工具不完全匹配。新工具会添加，旧工具会弃用。
 * 策略：
   * 提示： 灵活的提示可以尝试泛化，但可能难以处理全新的工具功能。
   * 微调： 需要强大的数据集更新策略和重新训练周期。微调中的少样本学习或领域自适应技术可能有所帮助。
   * 用于工具发现/描述的 RAG： 检索系统可以在运行时动态获取可用操作工具的描述，即使这些工具不在原始训练集中，也能为 LLM 提供最新信息。
   * 类 ToolGen 方法 ： 如果工具表示为令牌，添加新工具可能涉及扩展词汇表和进一步训练，但该框架专为大量工具而设计。
训练时工具知识与操作时工具可用性之间的差距需要动态适应机制，其中用于工具描述的 RAG 或持续学习管道变得至关重要。LLM，无论是通过提示还是微调，都是基于其接触到的工具信息进行学习的 。操作环境是动态的；工具会发生变化，新的工具会出现。静态模型将不可避免地遇到它不认识的工具或其规范已更改的工具。因此，需要机制来在运行时弥合这种知识差距（例如，RAG 获取当前工具文档）或通过频繁的模型更新（持续微调）。这突显了工具调用系统并非“一劳永逸”，而是需要持续的维护和适应策略。从一开始就为工具集演进进行设计至关重要。这包括对工具描述进行版本控制，建立更新微调数据集的管道，并可能采用 RAG 以减少 LLM 对其特定工具的静态训练时知识的依赖。
5.2. 应对工具的易变性和演化（工具 API、参数的变化）
工具 API 可能会发生变化（例如，新参数、弃用的端点、修改的输出格式）。这可能会破坏 LLM 正确调用它们的能力。
 * 策略：
   * 强大的工具定义管理： 对工具描述和模式进行版本控制。
   * 持续监控和测试： 定期测试工具集成以检测中断。
   * 自适应微调： 当发生重大工具更改时，重新训练或增量微调 LLM。
   * 错误处理和回退： 提示或微调应使 LLM 能够优雅地处理工具执行错误，并可能尝试替代方法或通知用户。ReAct 的观察步骤  在这里对于识别故障非常重要。
工具的易变性将 LLM 工具集成从一次性设置转变为持续的软件维护问题，需要版本控制、测试和敏捷的模型更新。LLM 学习基于特定的 API 签名和参数模式来调用工具 。如果这些签名/模式发生变化（工具易变性），LLM 学习到的模式将变得无效。这类似于传统软件集成在它们依赖的 API 发生变化时中断的方式。因此，管理 LLM 工具集成需要采用软件工程最佳实践，例如工具定义的版本控制、工具调用的自动化测试以及响应这些变化更新 LLM（通过提示或微调）的流程。外部工具的“活性”特性意味着 LLM 与它们的接口也必须是“活性的”。构建具有工具调用功能的 LLM 系统的团队需要整合 MLOps 实践，包括对外部工具 API 的强大监控和快速模型适应的管道。
5.3. 可扩展性：处理大量且多样化的工具
随着可用工具的数量增长到数万个，在提示中提供所有工具描述或对所有工具进行微调的传统方法变得不可行 。
 * 策略：
   * 检索增强的工具选择： 首先使用检索器根据用户查询从大型工具数据库中选择一小部分可能相关的工具。然后，仅将这些选定的工具描述提供给 LLM 。
   * 分层工具结构： 将工具组织到类别或层次结构中，以帮助 LLM 更有效地导航和选择它们。
   * ToolGen 框架 ： 通过将工具表示为令牌，专门设计用于扩展到大量工具，在许多情况下避免了显式检索的需要。
   * Taskmatrix.ai ： 旨在将基础模型与数百万个 API 连接起来，表明了对超大规模工具集成的研究。
有效管理大量工具需要从单一的 LLM 知识转向工具交互的“联邦式”或“检索优先”方法，其中 LLM 按需动态访问最相关工具的信息。LLM 具有有限的上下文窗口和处理能力 。将数千个工具的描述输入提示是不切实际的。对如此庞大且多样化的集合进行微调也极具挑战性。检索机制  允许系统首先从大型外部工具知识库中缩小可能性范围。然后，LLM 只需要考虑一小部分相关的工具。这种“即时”提供工具信息的方式使系统具有可扩展性。ToolGen  通过将工具编码到 LLM 的参数中提供了一种替代方案，但对于许多当前系统而言，检索是关键。对于需要访问大量、不断发展的工具集的应用程序，架构必须包括一个高效的工具检索/发现组件。LLM 成为一个智能代理，在决定特定的工具调用之前查询此组件。这指向了更复杂、多阶段的 AI 系统。
表 2：应对工具生态系统挑战的策略
| 挑战 | 挑战描述 | 对 LLM 性能的影响 | 缓解策略 (关联方法) | 实施关键考量 |
|---|---|---|---|---|
| 工具集差异 | 训练/微调时工具集与实际操作所需工具集不一致 | 可能无法调用所需工具，或错误调用不适用工具 | 动态工具描述获取 (RAG)，持续学习/微调，灵活的提示设计，ToolGen 类框架  | 工具描述版本控制，自动化数据集更新流程，RAG 检索效率 |
| 工具易变性 (API 变更等) | 工具的 API、参数、输出格式等发生变化 | 已学习的调用方式失效，导致执行错误或失败 | 工具定义版本控制，持续监控与测试，自适应微调，强大的错误处理机制 (如 ReAct 的观察步骤 )，提示中包含应对变化的指令 | 变更检测机制，快速模型更新能力，API 兼容性管理 |
| 工具数量过多/种类繁杂 | 需要管理的工具数量巨大，种类繁多，超出 LLM 上下文或直接处理能力 | 难以选择正确工具，上下文窗口溢出，效率低下 | 检索增强的工具选择 (Retrieval-Augmented Tool Selection) ，分层工具组织，ToolGen 框架 ，Taskmatrix.ai 等大规模集成研究  | 高效的工具检索系统，工具元数据管理，LLM 与检索器的协同 |
6. 高级考量与未来方向
6.1. 工具调用与检索增强生成 (RAG) 的协同作用
RAG 通过在生成前检索相关数据来增强 LLM 。将工具调用与 RAG 相结合，允许系统检索结构化/非结构化数据，然后对其采取行动或用其来为工具参数提供信息 。RAG 可以在生成响应或工具调用之前获取最相关的数据，从而产生更明智和准确的输出 。这创建了一个动态系统，能够主动与实时数据和服务交互 。这种结合使得 LLM 更加强大，因为它们既能“知道”更多（通过 RAG），也能“做”更多（通过工具）。
RAG 和工具调用的融合正在创造一类新的由 LLM 驱动的应用程序，这些应用程序可以动态收集信息，对其进行推理，然后通过外部工具对其采取行动，形成一个完整的感知-推理-行动循环。RAG 提供了“感知”或信息收集能力，获取相关的最新知识 。LLM 核心提供了“推理”能力，处理这些信息并决定行动方案。工具调用提供了“行动”能力，允许 LLM 根据其推理与外部系统交互 。这三个要素的结合反映了智能体的基本循环。这种协同作用克服了 LLM 仅依赖静态知识或与世界交互方式有限的局限性。这预示着将开发出更复杂和自主的 AI 代理，能够处理需要知识获取和外部交互的复杂多步骤任务。这是“智能体 AI” (agentic AI) 的关键推动因素 。
6.2. 由工具调用驱动的智能体 AI 系统的兴起
工具调用是智能体 AI 的关键推动因素，它允许自主系统通过动态访问外部资源并对其采取行动来完成复杂任务 。这些智能体可以自动化工作流程、与数据库交互并执行多步骤问题解决 。微调可以教会模型调用工具，从而将聊天机器人转变为能够采取行动的智能体 。这是 AI 领域的一个主要趋势，LLM 在其中充当自主智能体的“大脑”。
6.3. 伦理影响与安全考量
虽然现有材料中没有专门针对工具调用进行广泛讨论，但  讨论了安全代码生成和开发人员对 LLM 输出的过度依赖。推而广之，允许 LLM 通过工具行动会引入新的安全风险。如果 LLM 可以发送电子邮件  或下订单 ，那么安全保障措施至关重要。随着 LLM 通过工具获得在现实世界中执行操作的能力，确保它们安全、可靠且合乎道德地这样做至关重要。
赋予 LLM 工具调用能力固有地增加了其潜在的攻击面和风险状况，因此需要强大的安全协议、权限系统和人工监督机制，特别是对于那些能够影响现实世界变化的工具。在没有工具调用的情况下，LLM 的输出主要是信息性的。危害可能源于错误信息或有偏见的内容。通过工具调用，LLM 可以发起行动：发送电子邮件 、修改数据库、进行购买 。错误或恶意的工具调用可能会产生直接、具体且可能不可逆转的后果。这意味着安全考虑从仅仅是“LLM 的安全代码生成” 转变为“LLM 的安全行动执行”。因此，工具调用的强大功能必须与强有力的保障措施相平衡。采用工具调用 LLM 的系统需要仔细设计权限（LLM 可以访问哪些工具？它可以执行哪些操作？）、验证 LLM 生成的工具参数、速率限制、审计跟踪，以及可能对关键操作进行人工确认。最小权限原则变得极其重要。
7. 建议与结论
7.1. 实现稳健工具调用的关键要点
总结最关键的建议：从清晰的工具定义开始，根据需求选择正确的启用方法（提示、微调、混合），规划工具生态系统管理，并优先考虑安全性。这意味着开发者和研究者在着手实现工具调用功能时，应首先投入精力确保每一个工具的用途、参数和预期输出都有明确且机器可读的描述。随后，应基于任务的复杂性、可用资源以及对未来工具集变化的预期，审慎选择是通过精巧的提示工程、针对性的模型微调，还是结合两者的混合策略来赋予模型工具使用的能力。同时，必须预见到工具本身会不断变化和发展，因此需要建立相应的管理和更新机制。最后，由于工具调用赋予了模型直接影响外部系统的能力，因此安全性和伦理考量必须贯穿设计的始终，确保模型的行为可控、可预测且符合预期。
7.2. 未来研究与发展展望
讨论有前景的领域，例如更高级的工具学习（例如，从工具交互中自我学习，如 Toolformer  所暗示的），更好地处理工具组合，改进对工具使用的推理，以及标准化的工具集成框架。ToolGen  和持续学习  的工作表明了持续的创新。未来的研究可能会集中在使 LLM 能够更自主地学习新工具的用法，甚至通过观察或少量示例来推断如何组合多个工具以完成复杂任务。此外，提高 LLM 在决定何时、为何以及如何使用特定工具方面的推理能力，将是提升其作为智能体效能的关键。开发标准化的工具描述格式、API 接口以及集成框架，也将有助于降低工具集成的复杂性，促进更广泛的工具生态系统的形成和互操作性。随着这些领域的进展，我们可以期待 LLM 在与物理世界和数字世界交互方面展现出越来越强的能力和智能。
